#necessary libraries
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, GRU, Conv1D, MaxPooling1D, Flatten, Bidirectional, SimpleRNN, Dropout, BatchNormalization

# Function to calculate precision, recall, and accuracy
def calculate_metrics(y_true, y_pred):
    tp = np.sum((y_true == 1) & (y_pred == 1))
    tn = np.sum((y_true == 0) & (y_pred == 0))
    fp = np.sum((y_true == 0) & (y_pred == 1))
    fn = np.sum((y_true == 1) & (y_pred == 0))

    accuracy = (tp + tn) / (tp + tn + fp + fn)
    precision = tp / (tp + fp) if (tp + fp) != 0 else 0
    recall = tp / (tp + fn) if (tp + fn) != 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return accuracy, precision, recall, f1_score

# Load the dataset
file_path = "C:/Users/aimil/Downloads/diabetes.csv"
df = pd.read_csv(file_path)

# Split the data into features and target
X = df.drop(columns='Outcome').to_numpy()
Y = df['Outcome'].to_numpy()

# Manually split the data into training and test sets
def train_test_split_manual(X, Y, test_size=0.2, random_state=42):
    np.random.seed(random_state)
    indices = np.random.permutation(len(X))
    test_set_size = int(len(X) * test_size)
    test_indices = indices[:test_set_size]
    train_indices = indices[test_set_size:]
    return X[train_indices], X[test_indices], Y[train_indices], Y[test_indices]

X_train, X_test, Y_train, Y_test = train_test_split_manual(X, Y)

# List to store results
results = []

# Different model architectures
def build_sequential_dense():
    model = Sequential([
        Dense(12, input_dim=X_train.shape[1], activation='relu'),
        Dense(8, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_lstm():
    model = Sequential([
        LSTM(50, input_shape=(X_train.shape[1], 1), activation='relu', return_sequences=True),
        LSTM(50, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_gru():
    model = Sequential([
        GRU(50, input_shape=(X_train.shape[1], 1), activation='relu', return_sequences=True),
        GRU(50, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_conv1d():
    model = Sequential([
        Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X_train.shape[1], 1)),
        MaxPooling1D(pool_size=2),
        Flatten(),
        Dense(50, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_bidirectional_lstm():
    model = Sequential([
        Bidirectional(LSTM(50, activation='relu', return_sequences=True), input_shape=(X_train.shape[1], 1)),
        Bidirectional(LSTM(50, activation='relu')),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model
    
def build_bidirectional_gru():
    model = Sequential([
        Bidirectional(GRU(50, activation='relu', return_sequences=True), input_shape=(X_train.shape[1], 1)),
        Bidirectional(GRU(50, activation='relu')),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_simple_rnn():
    model = Sequential([
        SimpleRNN(50, input_shape=(X_train.shape[1], 1), activation='relu', return_sequences=True),
        SimpleRNN(50, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_deep_dense():
    model = Sequential([
        Dense(64, input_dim=X_train.shape[1], activation='relu'),
        Dense(32, activation='relu'),
        Dense(16, activation='relu'),
        Dense(8, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_dropout_regularization():
    model = Sequential([
        Dense(64, input_dim=X_train.shape[1], activation='relu'),
        Dropout(0.5),
        Dense(32, activation='relu'),
        Dropout(0.5),
        Dense(16, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

def build_batch_normalization():
    model = Sequential([
        Dense(64, input_dim=X_train.shape[1], activation='relu'),
        BatchNormalization(),
        Dense(32, activation='relu'),
        BatchNormalization(),
        Dense(16, activation='relu'),
        BatchNormalization(),
        Dense(1, activation='sigmoid')
    ])
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model

# List of model builders
model_builders = [
    build_sequential_dense,
    build_lstm,
    build_gru,
    build_conv1d,
    build_bidirectional_lstm,
    build_bidirectional_gru,
    build_simple_rnn,
    build_deep_dense,
    build_dropout_regularization,
    build_batch_normalization
]

# Train and evaluate each model
for build_model in model_builders:
    model = build_model()
    # Reshape data if necessary
    if 'input_shape=(8, 1)' in str(build_model):
        X_train_reshaped = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))
        X_test_reshaped = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))
    else:
        X_train_reshaped, X_test_reshaped = X_train, X_test

    # Fit the model
    model.fit(X_train_reshaped, Y_train, epochs=150, batch_size=10, verbose=0)
    
    # Predict the outcomes
    predictions = model.predict(X_test_reshaped)
    rounded_predictions = np.round(predictions).astype(int).flatten()
    
    # Calculate metrics
    accuracy, precision, recall, f1_score  = calculate_metrics(Y_test, rounded_predictions)
    
    # Store the results
    results.append({
        'model': build_model.__name__,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score
    })

for result in results:
    print(f"Model: {result['model']}, Accuracy: {result['accuracy']:.4f}, Precision: {result['precision']:.4f}, Recall: {result['recall']:.4f}, F1 score: {result['f1_score']:.4f}")
