# Importing necessary libraries
import h2o
from h2o.automl import H2OAutoML
from h2o.estimators.gbm import H2OGradientBoostingEstimator
from h2o.estimators.glm import H2OGeneralizedLinearEstimator
from h2o.estimators.deeplearning import H2ODeepLearningEstimator
from h2o.estimators.random_forest import H2ORandomForestEstimator
from h2o.estimators.naive_bayes import H2ONaiveBayesEstimator
from h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator
import pandas as pd
import numpy as np

# Initialize H2O
h2o.init()

# Load the dataset
file_path = "C:/Users/aimil/Downloads/train.csv"
df = h2o.import_file(file_path)

# Define predictors and response column
predictors = df.columns[:-1]
response = df.columns[-1]

# Convert response to a factor (for multiclass classification)
df[response] = df[response].asfactor()

# Split the data into training and validation sets
train, test = df.split_frame(ratios=[0.8], seed=1234)

# Function to calculate multiclass metrics 
def calculate_multiclass_metrics(y_true, y_pred):
    # Get unique classes
    classes = np.unique(y_true)
    
    # Initialize metrics
    precision_per_class = []
    recall_per_class = []
    f1_score_per_class = []
    total_true = 0
    total_pred = len(y_true)  # total number of samples
    
    # Iterate over each class to calculate precision, recall, and F1 score
    for cls in classes:
        # True Positives: Correctly predicted as this class
        TP = np.sum((y_true == cls) & (y_pred == cls))
        
        # False Positives: Predicted as this class but actually another class
        FP = np.sum((y_true != cls) & (y_pred == cls))
        
        # False Negatives: Actually this class but predicted as another class
        FN = np.sum((y_true == cls) & (y_pred != cls))
        
        # Precision: TP / (TP + FP)
        precision = TP / (TP + FP) if (TP + FP) > 0 else 0
        precision_per_class.append(precision)
        
        # Recall: TP / (TP + FN)
        recall = TP / (TP + FN) if (TP + FN) > 0 else 0
        recall_per_class.append(recall)
        
        # F1 Score: Harmonic mean of precision and recall
        if precision + recall > 0:
            f1 = 2 * (precision * recall) / (precision + recall)
        else:
            f1 = 0
        f1_score_per_class.append(f1)
        
        # Accuracy: Tracking correct predictions for the entire dataset
        total_true += TP  # Add true positives for accuracy
    
    # Overall Accuracy: Correct predictions divided by total predictions
    accuracy = total_true / total_pred
    
    # Average precision, recall, F1 score over all classes
    avg_precision = np.mean(precision_per_class)
    avg_recall = np.mean(recall_per_class)
    avg_f1_score = np.mean(f1_score_per_class)
    
    return accuracy, avg_precision, avg_recall, avg_f1_score

# List of different models
models = [
    ('GBM', H2OGradientBoostingEstimator(seed=1234, nfolds=5, keep_cross_validation_predictions=True)),
    ('GLM', H2OGeneralizedLinearEstimator(nfolds=5, keep_cross_validation_predictions=True)),
    ('Deep Learning', H2ODeepLearningEstimator(seed=1234, nfolds=5, keep_cross_validation_predictions=True)),
    ('Random Forest', H2ORandomForestEstimator(seed=1234, nfolds=5, keep_cross_validation_predictions=True)),
    ('Naive Bayes', H2ONaiveBayesEstimator(nfolds=5, keep_cross_validation_predictions=True)),
    ('AutoML (40 models)', H2OAutoML(max_models=40, seed=1234, balance_classes=True, nfolds=5))
]
# Dictionary to store model ids and special handling for AutoML
model_ids = {}

# Train base models for Stacked Ensemble with cross-validation and keep cross-validation predictions
base_gbm = H2OGradientBoostingEstimator(seed=1234, nfolds=5, keep_cross_validation_predictions=True)
base_rf = H2ORandomForestEstimator(seed=1234, nfolds=5, keep_cross_validation_predictions=True)
base_gbm.train(x=predictors, y=response, training_frame=train)
base_rf.train(x=predictors, y=response, training_frame=train)

# Save model IDs
base_model_ids = [base_gbm.model_id, base_rf.model_id]

# Train the Stacked Ensemble using base model IDs
stacked_ensemble = H2OStackedEnsembleEstimator(base_models=base_model_ids, seed=1234)
stacked_ensemble.train(x=predictors, y=response, training_frame=train)

# Add Stacked Ensemble model ID
model_ids['Stacked Ensemble'] = stacked_ensemble.model_id


# Train the models and store their IDs 
for name, model in models: 
    if name == 'AutoML (40 models)':
        model.train(x=predictors, y=response, training_frame=train)
        automl_leader = model.leader
        model_ids[name] = automl_leader.model_id
    else:
        model.train(x=predictors, y=response, training_frame=train)
        model_ids[name] = model.model_id

# Iterate over each model, train and evaluate
results = []
for name, model_id in model_ids.items():
    model = h2o.get_model(model_id)

    # Predict on the test set
    predictions = model.predict(test)

    # Extracting predictions (handling cases where predictions contain probabilities)
    if 'predict' in predictions.columns:
        y_pred = predictions['predict'].as_data_frame(use_pandas=True).values.flatten()
    else:
        y_pred = predictions.as_data_frame(use_pandas=True).values.flatten()

    # Get the true labels
    y_true = test[response].as_data_frame(use_pandas=True).values.flatten()

    # Calculate metrics
    accuracy = np.mean(y_true == y_pred)
    precision = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_pred == 1) if np.sum(y_pred == 1) > 0 else 0
    recall = np.sum((y_true == 1) & (y_pred == 1)) / np.sum(y_true == 1) if np.sum(y_true == 1) > 0 else 0
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    # Store the results
    results.append({
        'model': name,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score
    })

# Print the results
for result in results:
    print(f"Model: {result['model']}, Accuracy: {result['accuracy']:.4f}, Precision: {result['precision']:.4f}, Recall: {result['recall']:.4f}, F1 score: {result['f1_score']:.4f}")
